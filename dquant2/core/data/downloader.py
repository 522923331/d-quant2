"""æ•°æ®ä¸‹è½½æ¨¡å—

ç»Ÿä¸€çš„æ•°æ®ä¸‹è½½æ¥å£ï¼Œæ”¯æŒæ‰¹é‡ä¸‹è½½å’Œè¿›åº¦è¿½è¸ª
"""

import logging
from typing import List, Dict, Callable, Optional
from datetime import datetime
import time

import pandas as pd

from .cache import ParquetCache

logger = logging.getLogger(__name__)


class DataDownloader:
    """æ•°æ®ä¸‹è½½å™¨
    
    æä¾›ç»Ÿä¸€çš„æ•°æ®ä¸‹è½½æ¥å£ï¼Œæ”¯æŒå•åªã€æ‰¹é‡å’Œå¸‚åœºçº§åˆ«ä¸‹è½½
    æ”¯æŒæ™ºèƒ½å¢é‡æ›´æ–°
    """
    
    def __init__(self, data_provider, cache: Optional[ParquetCache] = None):
        """åˆå§‹åŒ–ä¸‹è½½å™¨
        
        Args:
            data_provider: æ•°æ®æä¾›è€…ï¼ˆAkShareDataProvider æˆ– BaostockDataProviderï¼‰
            cache: Parquetç¼“å­˜å®ä¾‹ï¼Œé»˜è®¤åˆ›å»ºæ–°å®ä¾‹
        """
        self.provider = data_provider
        self.cache = cache or ParquetCache()
        self._logged_in = False
    
    def _ensure_login(self):
        """ç¡®ä¿providerå·²ç™»å½•å¹¶åŠ è½½è‚¡ç¥¨åˆ—è¡¨"""
        if not self._logged_in:
            if hasattr(self.provider, 'login'):
                self.provider.login()
            if hasattr(self.provider, 'load_stock_names'):
                self.provider.load_stock_names()
            self._logged_in = True
    
    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self._logged_in and hasattr(self.provider, 'logout'):
            self.provider.logout()
            self._logged_in = False
    
    def _get_incremental_date_range(self, symbol: str, requested_start: str, requested_end: str) -> tuple:
        """æ™ºèƒ½å¢é‡æ›´æ–°ï¼šè®¡ç®—å®é™…éœ€è¦ä¸‹è½½çš„æ—¥æœŸèŒƒå›´
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            requested_start: è¯·æ±‚çš„å¼€å§‹æ—¥æœŸ
            requested_end: è¯·æ±‚çš„ç»“æŸæ—¥æœŸ
            
        Returns:
            (éœ€è¦ä¸‹è½½, å®é™…å¼€å§‹æ—¥æœŸ, å®é™…ç»“æŸæ—¥æœŸ)
        """
        import pandas as pd
        
        # æ£€æŸ¥ç¼“å­˜ä¸­çš„æ•°æ®
        cache_info = self.cache.get_cache_info(symbol)
        if not cache_info:
            # æ— ç¼“å­˜ï¼Œä¸‹è½½å…¨éƒ¨
            return (True, requested_start, requested_end)
        
        # æœ‰ç¼“å­˜ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å¢é‡æ›´æ–°
        req_start = pd.to_datetime(requested_start)
        req_end = pd.to_datetime(requested_end)
        cache_start = cache_info['start_date']
        cache_end = cache_info['end_date']
        
        # æƒ…å†µ1ï¼šç¼“å­˜å®Œå…¨è¦†ç›–è¯·æ±‚èŒƒå›´
        if cache_start <= req_start and cache_end >= req_end:
            logger.info(f"ğŸ“¦ {symbol} ç¼“å­˜å®Œå…¨è¦†ç›–ï¼Œæ— éœ€ä¸‹è½½")
            return (False, None, None)
        
        # æƒ…å†µ2ï¼šåªéœ€è¦ä¸‹è½½æ–°æ•°æ®ï¼ˆç¼“å­˜ç»“æŸæ—¥æœŸ < è¯·æ±‚ç»“æŸæ—¥æœŸï¼‰
        if cache_end < req_end:
            # ä»ç¼“å­˜ç»“æŸæ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹ä¸‹è½½
            new_start = (cache_end + pd.Timedelta(days=1)).strftime('%Y-%m-%d')
            logger.info(f"ğŸ“¥ {symbol} å¢é‡æ›´æ–°ï¼š{new_start} ~ {requested_end}")
            return (True, new_start, requested_end)
        
        # æƒ…å†µ3ï¼šéœ€è¦ä¸‹è½½å†å²æ•°æ®ï¼ˆç¼“å­˜å¼€å§‹æ—¥æœŸ > è¯·æ±‚å¼€å§‹æ—¥æœŸï¼‰
        if cache_start > req_start:
            # ä¸‹è½½åˆ°ç¼“å­˜å¼€å§‹æ—¥æœŸçš„å‰ä¸€å¤©
            new_end = (cache_start - pd.Timedelta(days=1)).strftime('%Y-%m-%d')
            logger.info(f"ğŸ“¥ {symbol} å†å²è¡¥å……ï¼š{requested_start} ~ {new_end}")
            return (True, requested_start, new_end)
        
        # é»˜è®¤ï¼šä¸‹è½½å…¨éƒ¨
        return (True, requested_start, requested_end)
    
    def download_single(
        self, 
        symbol: str, 
        start_date: str, 
        end_date: str,
        force: bool = False,
        incremental: bool = True
    ) -> Dict[str, any]:
        """ä¸‹è½½å•åªè‚¡ç¥¨æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ YYYYMMDD æˆ– YYYY-MM-DD
            end_date: ç»“æŸæ—¥æœŸ YYYYMMDD æˆ– YYYY-MM-DD
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
            incremental: æ˜¯å¦å¯ç”¨å¢é‡æ›´æ–°ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            ä¸‹è½½ç»“æœå­—å…¸: {'success': bool, 'symbol': str, 'rows': int, 'message': str}
        """
        try:
            # æ™ºèƒ½å¢é‡æ›´æ–°
            if not force and incremental:
                need_download, actual_start, actual_end = self._get_incremental_date_range(
                    symbol, start_date, end_date
                )
                
                if not need_download:
                    # ç¼“å­˜å®Œå…¨æ»¡è¶³éœ€æ±‚
                    cached_df = self.cache.load(symbol, start_date, end_date)
                    return {
                        'success': True,
                        'symbol': symbol,
                        'rows': len(cached_df) if cached_df is not None else 0,
                        'message': 'ç¼“å­˜å·²å­˜åœ¨'
                    }
                
                # ä½¿ç”¨å¢é‡èŒƒå›´
                start_date = actual_start
                end_date = actual_end
            
            # ç¡®ä¿provider ready
            self._ensure_login()
            
            # ä¸‹è½½æ•°æ®ï¼ˆproviderå†…éƒ¨ä¼šè‡ªåŠ¨ç¼“å­˜ï¼‰
            logger.info(f"â¬‡ï¸  å¼€å§‹ä¸‹è½½ {symbol}: {start_date} ~ {end_date}")
            df = self.provider.get_stock_data(symbol, start_date, end_date)
            
            if df is None or df.empty:
                logger.warning(f"âŒ {symbol} ä¸‹è½½å¤±è´¥ï¼šæ— æ•°æ®")
                return {
                    'success': False,
                    'symbol': symbol,
                    'rows': 0,
                    'message': 'æ— æ•°æ®'
                }
            
            logger.info(f"âœ… {symbol} ä¸‹è½½æˆåŠŸ: {len(df)} æ¡")
            
            return {
                'success': True,
                'symbol': symbol,
                'rows': len(df),
                'message': 'ä¸‹è½½æˆåŠŸ'
            }
            
        except Exception as e:
            logger.error(f"âŒ {symbol} ä¸‹è½½å¼‚å¸¸: {e}")
            return {
                'success': False,
                'symbol': symbol,
                'rows': 0,
                'message': str(e)
            }
    
    def download_batch(
        self,
        symbols: List[str],
        start_date: str,
        end_date: str,
        progress_callback: Optional[Callable[[str, int, int], None]] = None,
        force: bool = False,
        incremental: bool = True,
        cleanup: bool = True
    ) -> Dict[str, any]:
        """æ‰¹é‡ä¸‹è½½è‚¡ç¥¨æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°(message, current, total)
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            incremental: æ˜¯å¦å¯ç”¨å¢é‡æ›´æ–°
            cleanup: æ˜¯å¦åœ¨å®Œæˆåæ¸…ç†èµ„æºï¼ˆé»˜è®¤Trueï¼Œdownload_marketä¼šè®¾ä¸ºFalseï¼‰
            
        Returns:
            ä¸‹è½½ç»Ÿè®¡å­—å…¸: {'total': int, 'success': int, 'failed': int, 'cached': int, 'results': List[dict]}
        """
        total = len(symbols)
        success_count = 0
        failed_count = 0
        cached_count = 0
        results = []
        
        logger.info(f"ğŸ“¦ å¼€å§‹æ‰¹é‡ä¸‹è½½ {total} åªè‚¡ç¥¨")
        
        try:
            for i, symbol in enumerate(symbols):
                if progress_callback:
                    progress_callback(f"æ­£åœ¨ä¸‹è½½ {symbol}...", i + 1, total)
                
                result = self.download_single(symbol, start_date, end_date, force, incremental)
                results.append(result)
                
                if result['success']:
                    if result['message'] == 'ç¼“å­˜å·²å­˜åœ¨':
                        cached_count += 1
                    else:
                        success_count += 1
                else:
                    failed_count += 1
                
                # æ§åˆ¶ä¸‹è½½é€Ÿç‡ï¼Œé¿å…è¢«é™æµï¼ˆç¼“å­˜å‘½ä¸­ä¸å»¶è¿Ÿï¼‰
                if i < total - 1 and result['message'] != 'ç¼“å­˜å·²å­˜åœ¨':
                    time.sleep(0.2)
        finally:
            # åªåœ¨éœ€è¦æ—¶cleanupï¼ˆé¿å…download_marketæ—¶è¿‡æ—©å…³é—­ï¼‰
            if cleanup:
                self._cleanup()
        
        summary = {
            'total': total,
            'success': success_count,
            'failed': failed_count,
            'cached': cached_count,
            'results': results
        }
        
        logger.info(f"ğŸ“Š æ‰¹é‡ä¸‹è½½å®Œæˆ: æˆåŠŸ{success_count}, å¤±è´¥{failed_count}, ç¼“å­˜{cached_count}")
        return summary
    
        def download_one(symbol):
            """ä¸‹è½½å•ä¸ªè‚¡ç¥¨çš„åŒ…è£…å‡½æ•°"""
            result = self.download_single(symbol, start_date, end_date, force, incremental)
            
            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°è¿›åº¦
            with lock:
                completed[0] += 1
                if progress_callback:
                    progress_callback(f"å·²å®Œæˆ {completed[0]}/{total}ï¼Œæ­£åœ¨ä¸‹è½½ {symbol}...", 
                                    completed[0], total)
            
            return result
        
        try:
            # ç¡®ä¿providerå·²ç™»å½•ï¼ˆåœ¨å¹¶è¡Œæ‰§è¡Œå‰ï¼‰
            self._ensure_login()
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_symbol = {executor.submit(download_one, symbol): symbol 
                                   for symbol in symbols}
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_symbol):
                    symbol = future_to_symbol[future]
                    try:
                        result = future.result()
                        results.append(result)
                        
                        if result['success']:
                            if result['message'] == 'ç¼“å­˜å·²å­˜åœ¨':
                                cached_count += 1
                            else:
                                success_count += 1
                        else:
                            failed_count += 1
                            
                    except Exception as e:
                        logger.error(f"ä¸‹è½½ {symbol} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                        results.append({
                            'success': False,
                            'symbol': symbol,
                            'rows': 0,
                            'message': f'å¼‚å¸¸: {str(e)}'
                        })
                        failed_count += 1
                        
        finally:
            # åªåœ¨éœ€è¦æ—¶cleanup
            if cleanup:
                self._cleanup()
        
        summary = {
            'total': total,
            'success': success_count,
            'failed': failed_count,
            'cached': cached_count,
            'results': results
        }
        
        logger.info(f"ğŸ“Š å¹¶è¡Œä¸‹è½½å®Œæˆ: æˆåŠŸ{success_count}, å¤±è´¥{failed_count}, ç¼“å­˜{cached_count}")
        return summary
    
    
    def download_market(
        self,
        market: str,
        start_date: str,
        end_date: str,
        progress_callback: Optional[Callable[[str, int, int], None]] = None,
        force: bool = False,
        incremental: bool = True,
        max_stocks: Optional[int] = None
    ) -> Dict[str, any]:
        """ä¸‹è½½æ•´ä¸ªå¸‚åœºçš„æ•°æ®
        
        Args:
            market: å¸‚åœºä»£ç  'sh' æˆ– 'sz'
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            progress_callback: è¿›åº¦å›è°ƒ
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            incremental: æ˜¯å¦å¯ç”¨å¢é‡æ›´æ–°
            max_stocks: æœ€å¤§ä¸‹è½½æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            
        Returns:
            ä¸‹è½½ç»Ÿè®¡å­—å…¸
        """
        try:
            # ç¡®ä¿provider ready
            self._ensure_login()
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            if not hasattr(self.provider, 'get_stock_list'):
                logger.error("æ•°æ®æä¾›è€…ä¸æ”¯æŒ get_stock_list æ–¹æ³•")
                return {'total': 0, 'success': 0, 'failed': 0, 'cached': 0, 'results': []}
            
            symbols = self.provider.get_stock_list(market)
            
            if max_stocks:
                symbols = symbols[:max_stocks]
            
            logger.info(f"ğŸ“ˆ å‡†å¤‡ä¸‹è½½ {market.upper()} å¸‚åœº {len(symbols)} åªè‚¡ç¥¨")
            
            # è°ƒç”¨batchä¸‹è½½ï¼Œä½†ä¸è®©å®ƒcleanupï¼ˆæˆ‘ä»¬åœ¨è¿™é‡Œç»Ÿä¸€cleanupï¼‰
            summary = self.download_batch(
                symbols, start_date, end_date, 
                progress_callback, 
                force, 
                incremental,
                cleanup=False  # å…³é”®ï¼šä¸è®©batchæå‰cleanup
            )
            
            return summary
        except Exception as e:
            logger.error(f"ä¸‹è½½å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return {'total': 0, 'success': 0, 'failed': 0, 'cached': 0, 'results': []}
        finally:
            # åœ¨è¿™é‡Œç»Ÿä¸€cleanup
            self._cleanup()
